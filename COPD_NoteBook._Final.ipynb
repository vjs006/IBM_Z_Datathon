{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ab716ca",
   "metadata": {},
   "source": [
    "# **IBM Z Datathon - Datasmiths**\n",
    "\n",
    "---\n",
    "\n",
    "## Problem Statement:\n",
    "\n",
    "The primary objective of this challenge is to develop an automated diagnostic system for detecting chronic diseases like Chronic Obstructive Pulmonary Disease (COPD) and Cancer using deep learning techniques.\n",
    "\n",
    "Automated Diagnosis of COPD(Chronic Obstructive Pulmonary Disease) and Cancer\n",
    "using Deep Learning Techniques.\n",
    "Manual diagnosis of chronic diseases like COPD and cancer is time-consuming,\n",
    "resource-intensive, and prone to human error. Current diagnostic processes lack scalability and\n",
    "often lead to delayed treatment, reducing patient outcomes.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Team Members:\n",
    "- Chandravel Saravanan (Team Leader)\n",
    "- Chanakya R\n",
    "- Nithish Kumar S\n",
    "- Vijay Srinivas K\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset:\n",
    "\n",
    "The dataset consists of images of lung tissue from patients with either COPD or cancer. The images are labeled with their corresponding disease status (benign, malignant, or normal). The dataset is divided into training and testing sets, with 80% of the data used for training and 20% for testing. Find the link to the public dataset used https://www.kaggle.com/datasets/waseemnagahhenes/lung-cancer-dataset-iq-othnccd\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9645f97-69a2-41eb-99e9-493b8bdb8bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.9.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.12)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/jovyan/.local/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.0)\n",
      "Collecting protobuf<3.20,>=3.9.2 (from tensorflow)\n",
      "  Downloading protobuf-3.19.6-py2.py3-none-any.whl.metadata (828 bytes)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.23.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/jovyan/.local/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.51.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/jovyan/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
      "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n",
      "Installing collected packages: protobuf, gast\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.2\n",
      "    Uninstalling protobuf-3.20.2:\n",
      "      Successfully uninstalled protobuf-3.20.2\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.3\n",
      "    Uninstalling gast-0.5.3:\n",
      "      Successfully uninstalled gast-0.5.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "onnx 1.16.2 requires protobuf>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
      "onnxconverter-common 1.14.0 requires protobuf==3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
      "tf2onnx 1.16.1 requires protobuf~=3.20, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed gast-0.4.0 protobuf-3.19.6\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b097c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lung Cancer Dataset Splitting Script\n",
    "\n",
    "This script automates the process of splitting a dataset into training and testing subsets. It can be used to split images (or any files) from different classes into two directories: one for training and another for testing. The script uses an 80/20 split by default but can be adjusted as needed.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "#### Directory Setup:\n",
    "- Checks if the train and test directories exist, and creates them if not.\n",
    "\n",
    "#### Class Subfolder Processing:\n",
    "- Loops through each class (e.g., \"benign\", \"malignant\") in the source directory.\n",
    "- Creates corresponding subfolders in the train and test directories.\n",
    "\n",
    "#### Random Split:\n",
    "- Shuffles the images in each class.\n",
    "- Splits them into training and testing sets according to the specified ratio.\n",
    "\n",
    "#### File Transfer:\n",
    "- Moves the files to the appropriate train/test folders for each class.\n",
    "\n",
    "This ensures a clean and randomized split for building and evaluating models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62bf87c5-1367-40c3-a729-c4513e540998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 'Normal cases' split into 491 training and 123 testing images.\n",
      "Class 'Benign cases' split into 96 training and 25 testing images.\n",
      "Class '.ipynb_checkpoints' split into 0 training and 1 testing images.\n",
      "Class 'Malignant cases' split into 1071 training and 268 testing images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def split_dataset(source_dir, train_dir, test_dir, split_ratio=0.8):\n",
    "    # Create train and test directories if they don't exist\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "    \n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir)\n",
    "\n",
    "    # Loop through each class folder (e.g., benign, malignant, normal)\n",
    "    for class_name in os.listdir(source_dir):\n",
    "        class_path = os.path.join(source_dir, class_name)\n",
    "        \n",
    "        # Ensure the path is a directory (skip non-folder items)\n",
    "        if os.path.isdir(class_path):\n",
    "            # Create corresponding train/test subfolders for the class\n",
    "            train_class_dir = os.path.join(train_dir, class_name)\n",
    "            test_class_dir = os.path.join(test_dir, class_name)\n",
    "\n",
    "            os.makedirs(train_class_dir, exist_ok=True)\n",
    "            os.makedirs(test_class_dir, exist_ok=True)\n",
    "\n",
    "            # Get all files in the class folder\n",
    "            all_files = os.listdir(class_path)\n",
    "\n",
    "            # Shuffle the files to randomize the splitting\n",
    "            random.shuffle(all_files)\n",
    "\n",
    "            # Calculate the split index\n",
    "            split_index = int(len(all_files) * split_ratio)\n",
    "\n",
    "            # Split files into train and test\n",
    "            train_files = all_files[:split_index]\n",
    "            test_files = all_files[split_index:]\n",
    "\n",
    "            # Move files to the corresponding train and test folders\n",
    "            for file in train_files:\n",
    "                shutil.move(os.path.join(class_path, file), os.path.join(train_class_dir, file))\n",
    "\n",
    "            for file in test_files:\n",
    "                shutil.move(os.path.join(class_path, file), os.path.join(test_class_dir, file))\n",
    "\n",
    "            print(f\"Class '{class_name}' split into {len(train_files)} training and {len(test_files)} testing images.\")\n",
    "\n",
    "# Define the source folder and the destination train/test folders\n",
    "source_dir = 'Dataset/Data/Lung_cancer_dataset'    # Original dataset folder containing class subfolders\n",
    "train_dir = 'Dataset/Data/train'\n",
    "test_dir = 'Dataset/Data/test'\n",
    "\n",
    "# Call the function to split the dataset with an 80/20 train-test split\n",
    "split_dataset(source_dir, train_dir, test_dir, split_ratio=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229708dd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Creation, Training and Evaluation\n",
    "\n",
    "This script implements a Convolutional Neural Network (CNN) for multi-class image classification using TensorFlow and Keras. It includes:\n",
    "\n",
    "Data Preprocessing: Uses ImageDataGenerator to rescale image pixel values and set up generators for the training and validation datasets.\n",
    "Model Architecture: A sequential CNN model with three convolutional layers, max-pooling layers, a flattening layer, and a fully connected dense layer, ending with a softmax output for 4 classes.\n",
    "Compilation and Training: The model is compiled using the Adam optimizer and categorical cross-entropy loss. It is trained for 30 epochs with specified steps per epoch and evaluated on the validation data.\n",
    "Model Evaluation: The final validation accuracy is printed after model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be81a2ca-e58a-4eca-a4b4-f7cbc72b2949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 'Normal cases' split into 0 training and 0 testing images.\n",
      "Class 'Benign cases' split into 0 training and 0 testing images.\n",
      "Class '.ipynb_checkpoints' split into 0 training and 0 testing images.\n",
      "Class 'Malignant cases' split into 0 training and 0 testing images.\n",
      "Found 1658 images belonging to 4 classes.\n",
      "Found 416 images belonging to 4 classes.\n",
      "Epoch 1/30\n",
      " 52/100 [==============>...............] - ETA: 56s - loss: 0.7117 - accuracy: 0.7358WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3000 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 68s 664ms/step - loss: 0.7117 - accuracy: 0.7358 - val_loss: 0.4526 - val_accuracy: 0.8269\n",
      "13/13 [==============================] - 5s 408ms/step - loss: 0.4526 - accuracy: 0.8269\n",
      "Validation Accuracy: 82.69%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Split dataset with 80% for training and 20% for testing\n",
    "split_dataset(source_dir, train_dir, test_dir, split_ratio=0.8)\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')  # For multiclass classification\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')  # Ensure it's categorical for multi-class\n",
    "\n",
    "# Define CNN model\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "\n",
    "# Output layer for 4 classes (update the number based on actual classes)\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,  # Adjust based on your dataset size\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b545e0d6",
   "metadata": {},
   "source": [
    "---\n",
    "The output provides insights into the dataset splitting, model training, and validation performance:\n",
    "\n",
    "Dataset Splitting:\n",
    "- The classes Normal cases, Benign cases, and Malignant cases were expected to contain images but ended up with 0 images split into training or testing sets. This might be due to an incorrect source directory, empty folders, or a file-reading issue.\n",
    "- The .ipynb_checkpoints folder, a hidden folder created by Jupyter, was mistakenly included. It should be ignored in future runs.\n",
    "\n",
    "Image Counts:\n",
    "- Training Set: 1658 images were successfully loaded across 4 classes (likely including .ipynb_checkpoints).\n",
    "- Validation Set: 416 images were found across 4 classes.\n",
    "\n",
    "Training Output (Epoch 1):\n",
    "- Accuracy: The model achieved 73.58% accuracy during training after the first epoch.\n",
    "- Loss: The training loss was 0.7117, which measures how far predictions are from the actual labels. Lower loss is better.\n",
    "\n",
    "Validation Output:\n",
    "- Val Accuracy: The model achieved 82.69% accuracy on the validation set, meaning it correctly predicted 82.69% of validation images.\n",
    "- Val Loss: The validation loss was 0.4526, indicating that the model performs well on unseen data.\n",
    "\n",
    "Overall, the model is performing well after the first epoch with a validation accuracy of 82.69%. However, there are potential issues with the dataset split (no images found for certain classes), which need to be addressed.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e801d2b5",
   "metadata": {},
   "source": [
    "### Improved Model:\n",
    "\n",
    "The model is improved and more robust with the fix of the dataset split algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fdb4a91-77bb-443c-8362-d7ddfa5fe385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1660 images belonging to 4 classes.\n",
      "Found 416 images belonging to 4 classes.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_25 (Conv2D)          (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 148, 148, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 146, 146, 32)      9248      \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 146, 146, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 73, 73, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 73, 73, 32)        0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 71, 71, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 69, 69, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 69, 69, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 34, 34, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 34, 34, 64)        0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 32, 32, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 30, 30, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 30, 30, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 15, 15, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 15, 15, 128)       0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 28800)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               14746112  \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,039,012\n",
      "Trainable params: 15,037,092\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.0528 - accuracy: 0.6763WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 15 batches). You may need to use the repeat() function when building your dataset.\n",
      "51/51 [==============================] - 233s 5s/step - loss: 1.0528 - accuracy: 0.6763 - val_loss: 2.8958 - val_accuracy: 0.6442\n",
      "Epoch 2/30\n",
      "51/51 [==============================] - 230s 4s/step - loss: 0.6397 - accuracy: 0.8096\n",
      "Epoch 3/30\n",
      "51/51 [==============================] - 185s 4s/step - loss: 0.4547 - accuracy: 0.8446\n",
      "Epoch 4/30\n",
      "51/51 [==============================] - 173s 3s/step - loss: 0.4663 - accuracy: 0.8421\n",
      "Epoch 5/30\n",
      "51/51 [==============================] - 240s 5s/step - loss: 0.4831 - accuracy: 0.8348\n",
      "Epoch 6/30\n",
      "51/51 [==============================] - 208s 4s/step - loss: 0.4301 - accuracy: 0.8483\n",
      "Epoch 7/30\n",
      "51/51 [==============================] - 276s 5s/step - loss: 0.3811 - accuracy: 0.8655\n",
      "Epoch 8/30\n",
      "51/51 [==============================] - 171s 3s/step - loss: 0.3687 - accuracy: 0.8618\n",
      "Epoch 9/30\n",
      "51/51 [==============================] - 169s 3s/step - loss: 0.3322 - accuracy: 0.8747\n",
      "Epoch 10/30\n",
      "51/51 [==============================] - 346s 7s/step - loss: 0.3391 - accuracy: 0.8790\n",
      "Epoch 11/30\n",
      "51/51 [==============================] - 397s 8s/step - loss: 0.3319 - accuracy: 0.8747\n",
      "Epoch 12/30\n",
      "51/51 [==============================] - 201s 4s/step - loss: 0.2760 - accuracy: 0.9005\n",
      "Epoch 13/30\n",
      "51/51 [==============================] - 416s 8s/step - loss: 0.3092 - accuracy: 0.8870\n",
      "Epoch 14/30\n",
      "51/51 [==============================] - 240s 5s/step - loss: 0.2887 - accuracy: 0.8919\n",
      "Epoch 15/30\n",
      "51/51 [==============================] - 373s 7s/step - loss: 0.2760 - accuracy: 0.9011\n",
      "Epoch 16/30\n",
      "51/51 [==============================] - 175s 3s/step - loss: 0.2491 - accuracy: 0.9036\n",
      "Epoch 17/30\n",
      "51/51 [==============================] - 190s 4s/step - loss: 0.2658 - accuracy: 0.9048\n",
      "Epoch 18/30\n",
      "51/51 [==============================] - 243s 5s/step - loss: 0.2456 - accuracy: 0.8980\n",
      "Epoch 19/30\n",
      "51/51 [==============================] - 168s 3s/step - loss: 0.2224 - accuracy: 0.9183\n",
      "Epoch 20/30\n",
      "51/51 [==============================] - 168s 3s/step - loss: 0.2221 - accuracy: 0.9115\n",
      "Epoch 21/30\n",
      "51/51 [==============================] - 167s 3s/step - loss: 0.2730 - accuracy: 0.9005\n",
      "Epoch 22/30\n",
      "51/51 [==============================] - 183s 4s/step - loss: 0.1939 - accuracy: 0.9189\n",
      "Epoch 23/30\n",
      "51/51 [==============================] - 209s 4s/step - loss: 0.2066 - accuracy: 0.9177\n",
      "Epoch 24/30\n",
      "51/51 [==============================] - 170s 3s/step - loss: 0.2183 - accuracy: 0.9177\n",
      "Epoch 25/30\n",
      "51/51 [==============================] - 171s 3s/step - loss: 0.2134 - accuracy: 0.9238\n",
      "Epoch 26/30\n",
      "51/51 [==============================] - 235s 5s/step - loss: 0.2124 - accuracy: 0.9201\n",
      "Epoch 27/30\n",
      "51/51 [==============================] - 168s 3s/step - loss: 0.2638 - accuracy: 0.9036\n",
      "Epoch 28/30\n",
      "51/51 [==============================] - 169s 3s/step - loss: 0.2357 - accuracy: 0.9011\n",
      "Epoch 29/30\n",
      "51/51 [==============================] - 228s 4s/step - loss: 0.2030 - accuracy: 0.9189\n",
      "Epoch 30/30\n",
      "51/51 [==============================] - 176s 3s/step - loss: 0.2236 - accuracy: 0.9158\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.5488 - accuracy: 0.8462\n",
      "Validation Accuracy: 84.62%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "\n",
    "# Define an improved CNN model\n",
    "model = models.Sequential()\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,          # Reduced rotation\n",
    "    width_shift_range=0.1,      # Reduced horizontal shifts\n",
    "    height_shift_range=0.1,     # Reduced vertical shifts\n",
    "    shear_range=0.1,            # Reduced shear\n",
    "    zoom_range=0.1,             # Reduced zoom\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')  # For multiclass classification\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')  # Ensure it's categorical for multi-class\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))  # Adding dropout to prevent overfitting\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))  # Adding dropout before the final layer\n",
    "\n",
    "# Output layer for 4 classes (softmax for multiclass classification)\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "# Assuming you already defined train_generator and validation_generator\n",
    "\n",
    "# Define the total number of images\n",
    "total_train_images = 1660  # Total number of training images\n",
    "total_validation_images = 500  # Update this with your actual validation set size\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Calculate steps per epoch\n",
    "train_steps = total_train_images // batch_size\n",
    "validation_steps = total_validation_images // batch_size\n",
    "\n",
    "# Train the model with correct steps\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,           # Set based on the number of training samples\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps      # Set based on the number of validation samples\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f'Validation Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875d444f",
   "metadata": {},
   "source": [
    "This output provides detailed information about the model architecture and performance after training:\n",
    "\n",
    "### 1. **Dataset Information**:\n",
    "   - **Training Set**: 1660 images are correctly loaded across 4 classes.\n",
    "   - **Validation Set**: 416 images are available for validation, also across 4 classes.\n",
    "\n",
    "### 2. **Model Architecture**:\n",
    "   - The model is sequential with multiple layers, including convolutional, batch normalization, max-pooling, and dropout layers.\n",
    "   - **Conv2D Layers**: The network has multiple convolutional layers (Conv2D), each followed by batch normalization, to ensure stable training and faster convergence.\n",
    "   - **Dropout Layers**: These help reduce overfitting by randomly deactivating some neurons during training, adding regularization.\n",
    "   - **Total Parameters**: The model summary lists the parameters in each layer (weights, biases, etc.). These values indicate how complex the model is.\n",
    "\n",
    "### 3. **Training Output**:\n",
    "   - **Final Epoch (30/30)**: \n",
    "     - **Training Loss**: The loss decreased to **0.2236**, indicating good convergence during training.\n",
    "     - **Training Accuracy**: The model achieved **91.58% accuracy** on the training set, showing strong performance on the data it was trained on.\n",
    "\n",
    "### 4. **Validation Output**:\n",
    "   - **Validation Loss**: After the last epoch, the validation loss is **0.5488**, showing a moderate degree of error on unseen data.\n",
    "   - **Validation Accuracy**: The model achieved **84.62% accuracy** on the validation set, indicating it generalizes fairly well to new data.\n",
    "\n",
    "Overall, the model has been successfully trained, achieving high accuracy on both the training and validation sets, with slight room for improvement in validation performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4d55ce",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## **Image Prediction using a Pre-trained Model**\n",
    "\n",
    "This script allows you to load an image, preprocess it, and make predictions using a pre-trained model (such as a CNN). The predicted class and its confidence level are then displayed, along with the image.\n",
    "\n",
    "#### Key Components:\n",
    "1. **Libraries Used:**\n",
    "   - `numpy`: Used for numerical operations and array manipulations.\n",
    "   - `tensorflow.keras.preprocessing`: For loading and preprocessing images.\n",
    "   - `matplotlib.pyplot`: For displaying the image and the prediction.\n",
    "\n",
    "2. **Class Labels:**\n",
    "   - The model predicts one of three classes: `'benign'`, `'malignant'`, or `'normal'`. These labels can be adjusted based on the actual classes of your dataset.\n",
    "\n",
    "3. **Image Preprocessing:**\n",
    "   - The image is resized to `(150, 150)` pixels to match the input shape of the model.\n",
    "   - The image is converted to a NumPy array and normalized by dividing the pixel values by 255 to ensure they are between 0 and 1.\n",
    "\n",
    "4. **Prediction:**\n",
    "   - The `predict()` function of the pre-trained model is used to make a prediction.\n",
    "   - The class with the highest probability is chosen as the predicted label using `np.argmax()`.\n",
    "\n",
    "5. **Display:**\n",
    "   - The predicted class and its confidence level are printed.\n",
    "   - The original image is displayed with the prediction as the title using `matplotlib`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837a268c-97e7-4589-9d76-18d5a80307b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the trained model\n",
    "# Assuming your model is already loaded in 'model'\n",
    "\n",
    "# Class labels (you can replace these with your actual class names)\n",
    "class_labels = ['benign', 'malignant', 'normal']\n",
    "\n",
    "def predict_image(img_path):\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(img_path, target_size=(150, 150))  # Resize to match model input size\n",
    "    img_array = image.img_to_array(img)  # Convert to numpy array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array /= 255.0  # Normalize the image\n",
    "    \n",
    "    # Make the prediction\n",
    "    prediction = model.predict(img_array)\n",
    "    \n",
    "    # Get the class with the highest probability\n",
    "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "    predicted_label = class_labels[predicted_class]\n",
    "    \n",
    "    # Print and show the prediction\n",
    "    print(f\"Predicted: {predicted_label} (Confidence: {np.max(prediction)*100:.2f}%)\")\n",
    "    \n",
    "    # Display the image\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Prediction: {predicted_label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "img_path = 'path_to_your_test_image.jpg'  # Replace with the actual path to your image\n",
    "predict_image(img_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
